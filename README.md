# ASCR Admin Portal - Microservices Architecture

The **Australian Stem Cell Registry (ASCR) Admin Portal** is a modern microservices-based web application for managing cell line data and AI-powered curation workflows. Built with FastAPI and Next.js, it provides a lightweight, scalable solution for cell line metadata management.

## ğŸ—ï¸ Architecture

### Microservices Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  frontend   â”‚â—„â”€â”€â”€â”¤ curation_service â”‚â—„â”€â”€â”€â”¤ background_processorâ”‚
â”‚  (Next.js)  â”‚    â”‚    (FastAPI)     â”‚    â”‚   (Celery+Redis)   â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                     
      â–¼                     
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         
â”‚cell_line_archiveâ”‚         
â”‚   (FastAPI)     â”‚         
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         
```

### Services

ğŸ¨ **Frontend** (`services/frontend/`)
- **Port**: 3001
- **Tech**: Next.js 15 + TypeScript + Tailwind CSS
- **Purpose**: User interface for cell line management and curation workflows

ğŸ¤– **Curation Service** (`services/curation_service/`)
- **Port**: 8001
- **Tech**: FastAPI + OpenAI
- **Purpose**: AI-powered extraction of cell line metadata from text

ğŸ“ **Cell Line Archive** (`services/cell_line_archive/`)
- **Port**: 8002
- **Tech**: FastAPI + File Storage
- **Purpose**: CRUD operations and version control for cell line data

âš™ï¸ **Background Processor** (`services/background_processor/`)
- **Tech**: Celery + Redis
- **Purpose**: Long-running AI curation tasks and job processing

ğŸ”´ **Redis**
- **Port**: 6380
- **Purpose**: Task queue and caching for background jobs

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- Text editor for configuration

### Get Started

1. **Clone and enter directory**
   ```bash
   git clone <repository-url>
   cd ascr-admin-portal
   ```

2. **Start all services**
   ```bash
   ./start.sh
   ```

3. **Configure API keys** (edit `.env` file)
   ```bash
   OPENAI_API_KEY=your_actual_openai_key
   ANTHROPIC_API_KEY=your_actual_anthropic_key
   ```

4. **Access the application**
   - **Frontend**: http://localhost:3001
   - **Curation API**: http://localhost:8001/docs
   - **Archive API**: http://localhost:8002/docs

## ğŸ“‹ Features

- **ğŸ¤– AI-Powered Curation**: Extract cell line metadata from text using OpenAI GPT-4
- **ğŸ“ File-Based Storage**: Simple JSON file storage with automatic versioning
- **âœï¸ Advanced Editor**: Cell line editing with real-time diff visualization
- **ğŸ”„ Version Control**: Automatic versioning system (keeps last 10 versions)
- **âš¡ Background Processing**: Asynchronous handling of long-running curation tasks
- **ğŸ“Š Statistics**: Archive analytics and status tracking
- **ğŸ” Search & Filter**: Query cell lines by status, content, and metadata

## ğŸ› ï¸ Development

### Local Development

**Start services:**
```bash
docker-compose up -d
```

**View logs:**
```bash
docker-compose logs -f [service_name]
```

**Stop services:**
```bash
docker-compose down
```

### Project Structure

```
ascr-admin-portal/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ frontend/              # Next.js application
â”‚   â”œâ”€â”€ curation_service/      # AI curation FastAPI service
â”‚   â”œâ”€â”€ cell_line_archive/     # Data management FastAPI service
â”‚   â””â”€â”€ background_processor/  # Celery worker for long tasks
â”œâ”€â”€ sample_data/               # Example cell line data files
â”œâ”€â”€ docker-compose.yml         # Service orchestration
â”œâ”€â”€ start.sh                   # Quick start script
â””â”€â”€ README.md                  # This file
```

### Data Storage

- **Cell Lines**: `/data/cell_lines/*.json` - Individual cell line records
- **Versions**: `/data/versions/{cell_line_id}/v*.json` - Version history
- **Jobs**: Redis-based temporary storage for curation job status

## ğŸ“¡ API Endpoints

### Curation Service (Port 8001)
- `POST /curate` - Start AI curation job for text content
- `GET /status/{job_id}` - Check curation job status
- `GET /jobs` - List recent curation jobs
- `DELETE /jobs/{job_id}` - Remove completed job

### Archive Service (Port 8002)
- `GET /cell-lines/` - List all cell lines (with pagination/filtering)
- `POST /cell-lines/` - Create new cell line
- `GET /cell-lines/{id}` - Get specific cell line
- `PUT /cell-lines/{id}` - Update cell line
- `DELETE /cell-lines/{id}` - Archive cell line
- `GET /cell-lines/{id}/versions` - Get version history
- `GET /stats` - Archive statistics

## ğŸ”§ Configuration

### Environment Variables

```bash
# Required for AI curation
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key

# Service configuration
REDIS_URL=redis://redis:6379/0
DEBUG=true
```

### Volumes

- `archive_data` - Persistent storage for cell line data
- `curation_data` - Temporary storage for curation jobs
- `redis_data` - Redis persistence
- `frontend_node_modules` - Node.js dependencies cache

## ğŸ§ª Sample Data

The `sample_data/` directory contains example cell line records that can be imported for testing:

```bash
# Example: Create a cell line from sample data
curl -X POST "http://localhost:8002/cell-lines/" \
  -H "Content-Type: application/json" \
  -d @sample_data/TEST001-A.json
```

## âš¡ Performance Features

- **File-based storage** - No database overhead
- **Microservices** - Independent scaling and deployment
- **Background processing** - Non-blocking AI operations
- **Containerized** - Consistent development and deployment
- **Version control** - Automatic cleanup (10-version retention)

## ğŸ”’ Security Notes

- Configure proper API keys before production use
- Implement authentication for production deployments
- Review network security for container communication
- Backup data volumes regularly

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Follow existing code patterns
4. Test your changes
5. Submit a pull request

## ğŸ“„ License

[Add your license information here]

---

**Simplified Architecture**: This microservices approach replaces the previous Django + PostgreSQL setup with a much lighter, more maintainable system focused on essential functionality.